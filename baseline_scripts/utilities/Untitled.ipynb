{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_clean(text, stops=False, stemming=False):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\" US \", \" american \", text)\n",
    "    text = text.lower().split()\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"don't\", \"do not \", text)\n",
    "    text = re.sub(r\"aren't\", \"are not \", text)\n",
    "    text = re.sub(r\"isn't\", \"is not \", text)\n",
    "    text = re.sub(r\"%\", \" percent \", text)\n",
    "    text = re.sub(r\"that's\", \"that is \", text)\n",
    "    text = re.sub(r\"doesn't\", \"does not \", text)\n",
    "    text = re.sub(r\"he's\", \"he is \", text)\n",
    "    text = re.sub(r\"she's\", \"she is \", text)\n",
    "    text = re.sub(r\"it's\", \"it is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = text.lower().split()\n",
    "    text = [w for w in text if len(w) >= 2]\n",
    "    if stemming and stops:\n",
    "        text = [word for word in text if word not in stopwords.words('english')]\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        englishStemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "        text = [englishStemmer.stem(word) for word in text]\n",
    "        text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "        # text = [lancaster.stem(word) for word in text]\n",
    "        text = [word for word in text if word not in stopwords.words('english')]\n",
    "    elif stops:\n",
    "        text = [word for word in text if word not in stopwords.words('english')]\n",
    "    elif stemming:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        englishStemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "        text = [englishStemmer.stem(word) for word in text]\n",
    "        text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preproccesor:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Init function\n",
    "        \"\"\"\n",
    "\n",
    "    def load_data(preprocessed = True):\n",
    "        data = pd.read_csv(\"../../ethos_data/Davidson_Dataset_Binary.csv\", delimiter='âˆ«')\n",
    "        data = shuffle(data)\n",
    "\n",
    "        XT = data['comment'].values\n",
    "        X = []\n",
    "        yT = data['isHate'].values\n",
    "        y = []\n",
    "        for yt in yT:\n",
    "            if yt>=0.5:\n",
    "                y.append(int(1))\n",
    "            else:\n",
    "                y.append(int(0))\n",
    "        for x in XT:\n",
    "            if preprocessed:\n",
    "                X.append(my_clean(text=str(x), stops=False, stemming=True))\n",
    "            else:\n",
    "                X.append(x)\n",
    "        return numpy.array(X),numpy.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X, y = Preproccesor.load_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24783"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22304 2479\n",
      "22304 2479\n",
      "22304 2479\n",
      "22305 2478\n",
      "22305 2478\n",
      "22305 2478\n",
      "22305 2478\n",
      "22305 2478\n",
      "22305 2478\n",
      "22305 2478\n"
     ]
    }
   ],
   "source": [
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "    X_train, X_valid = X[train_index], X[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    print(len(X_train), len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
