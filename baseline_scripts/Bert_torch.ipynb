{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from utilities.preprocess import Preproccesor\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"../ethos_data/Ethos_Dataset_Binary.csv\", delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"isHate\"] = np.where((df.isHate>=0.5), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X,y = df['comment'].values, df['isHate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Preproccesor.load_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'comment': X, 'isHate': y})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df['comment'].values, df['isHate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['comment'], df['isHate'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['isHate'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "n_fold = 10\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-199021fef517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_labels' is not defined"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(val_labels, return_counts=True)\n",
    "print(unique)\n",
    "plt.bar(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
    "\n",
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True)\n",
    "\n",
    "# output\n",
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-18f423854ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_text' is not defined"
     ]
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 100,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 100,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 100,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "    \n",
    "      self.fc2 = nn.Linear(512,256)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc3 = nn.Linear(256,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      x = self.fc3(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train(train_dataloader):\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate(val_dataloader):\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Wed Oct 14 14:28:04 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1\n",
      " 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0\n",
      " 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1\n",
      " 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0\n",
      " 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0\n",
      " 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0\n",
      " 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 1\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0\n",
      " 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 1\n",
      " 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 1 1 0 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
      " 1 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1\n",
      " 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0\n",
      " 0 0 1 1 0 1 1 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.88385827 1.15128205]\n",
      "\n",
      " Epoch 1 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.694\n",
      "Validation Loss: 0.686\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.692\n",
      "Validation Loss: 0.682\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.691\n",
      "Validation Loss: 0.678\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.688\n",
      "Validation Loss: 0.675\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.691\n",
      "Validation Loss: 0.673\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.690\n",
      "Validation Loss: 0.671\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.689\n",
      "Validation Loss: 0.668\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.684\n",
      "Validation Loss: 0.667\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.683\n",
      "Validation Loss: 0.665\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.680\n",
      "Validation Loss: 0.663\n",
      "0.74\n",
      "Fold 1 started at Wed Oct 14 14:28:44 2020\n",
      "Class Weights: [0.88385827 1.15128205]\n",
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0\n",
      " 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1\n",
      " 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0\n",
      " 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1\n",
      " 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
      " 1 0 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1\n",
      " 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1\n",
      " 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 1\n",
      " 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
      " 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.679\n",
      "Validation Loss: 0.680\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.678\n",
      "Validation Loss: 0.679\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.677\n",
      "Validation Loss: 0.678\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.677\n",
      "Validation Loss: 0.677\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.675\n",
      "Validation Loss: 0.675\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.678\n",
      "Validation Loss: 0.674\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.677\n",
      "Validation Loss: 0.672\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.674\n",
      "Validation Loss: 0.671\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.674\n",
      "Validation Loss: 0.669\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 0.668\n",
      "0.54\n",
      "Fold 2 started at Wed Oct 14 14:29:24 2020\n",
      "Class Weights: [0.88385827 1.15128205]\n",
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 1\n",
      " 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1\n",
      " 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0\n",
      " 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0\n",
      " 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0\n",
      " 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0\n",
      " 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0\n",
      " 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0\n",
      " 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0\n",
      " 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0\n",
      " 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1\n",
      " 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0\n",
      " 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0\n",
      " 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.675\n",
      "Validation Loss: 0.665\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.677\n",
      "Validation Loss: 0.663\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.672\n",
      "Validation Loss: 0.667\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.666\n",
      "Validation Loss: 0.666\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.664\n",
      "Validation Loss: 0.664\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.665\n",
      "Validation Loss: 0.663\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.664\n",
      "Validation Loss: 0.659\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.664\n",
      "Validation Loss: 0.657\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.659\n",
      "Validation Loss: 0.657\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.656\n",
      "Validation Loss: 0.659\n",
      "0.69\n",
      "Fold 3 started at Wed Oct 14 14:29:58 2020\n",
      "Class Weights: [0.88385827 1.15128205]\n",
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0\n",
      " 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 1\n",
      " 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1\n",
      " 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1\n",
      " 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0\n",
      " 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0\n",
      " 1 1 0 1 1 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1\n",
      " 0 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0\n",
      " 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0\n",
      " 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1\n",
      " 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 1\n",
      " 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1\n",
      " 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0\n",
      " 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0\n",
      " 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 1 0 1 0 1 1 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.663\n",
      "Validation Loss: 0.649\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.660\n",
      "Validation Loss: 0.649\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.664\n",
      "Validation Loss: 0.652\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.651\n",
      "Validation Loss: 0.653\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.654\n",
      "Validation Loss: 0.651\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.655\n",
      "Validation Loss: 0.647\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.639\n",
      "Validation Loss: 0.657\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.655\n",
      "Validation Loss: 0.643\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.650\n",
      "Validation Loss: 0.646\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.644\n",
      "Validation Loss: 0.639\n",
      "0.64\n",
      "Fold 4 started at Wed Oct 14 14:30:29 2020\n",
      "Class Weights: [0.88385827 1.15128205]\n",
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0\n",
      " 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1\n",
      " 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0\n",
      " 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
      " 0 0 0 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0\n",
      " 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0\n",
      " 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1 0\n",
      " 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0\n",
      " 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1\n",
      " 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0\n",
      " 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 1 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 1\n",
      " 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 0 0 0\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0\n",
      " 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 1 1 0 1 1 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.652\n",
      "Validation Loss: 0.646\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.650\n",
      "Validation Loss: 0.644\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.642\n",
      "Validation Loss: 0.646\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.642\n",
      "Validation Loss: 0.644\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.640\n",
      "Validation Loss: 0.644\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.643\n",
      "Validation Loss: 0.643\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.657\n",
      "Validation Loss: 0.645\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.653\n",
      "Validation Loss: 0.642\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.633\n",
      "Validation Loss: 0.640\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.640\n",
      "Validation Loss: 0.639\n",
      "0.65\n",
      "Fold 5 started at Wed Oct 14 14:31:04 2020\n",
      "Class Weights: [0.88212181 1.15424165]\n",
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 0\n",
      " 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1\n",
      " 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 1 0\n",
      " 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0\n",
      " 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0\n",
      " 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1\n",
      " 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1\n",
      " 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0\n",
      " 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0\n",
      " 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 0\n",
      " 0 1 1 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0\n",
      " 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0\n",
      " 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1\n",
      " 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0\n",
      " 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1\n",
      " 0 1 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 1 1 0 1 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.641\n",
      "Validation Loss: 0.644\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.645\n",
      "Validation Loss: 0.649\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.626\n",
      "Validation Loss: 0.641\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.633\n",
      "Validation Loss: 0.652\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.640\n",
      "Validation Loss: 0.638\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.636\n",
      "Validation Loss: 0.648\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.656\n",
      "Validation Loss: 0.643\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.636\n",
      "Validation Loss: 0.654\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.629\n",
      "Validation Loss: 0.641\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.623\n",
      "Validation Loss: 0.648\n",
      "0.71\n",
      "Fold 6 started at Wed Oct 14 14:31:33 2020\n",
      "Class Weights: [0.88212181 1.15424165]\n",
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0\n",
      " 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1\n",
      " 0 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1\n",
      " 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 1\n",
      " 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 0 1\n",
      " 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1\n",
      " 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1\n",
      " 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1\n",
      " 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1\n",
      " 0 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1\n",
      " 0 0 1 1 0 1 1 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.638\n",
      "Validation Loss: 0.594\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.630\n",
      "Validation Loss: 0.593\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.633\n",
      "Validation Loss: 0.590\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.633\n",
      "Validation Loss: 0.585\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.643\n",
      "Validation Loss: 0.586\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.625\n",
      "Validation Loss: 0.580\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.619\n",
      "Validation Loss: 0.593\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.629\n",
      "Validation Loss: 0.582\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.628\n",
      "Validation Loss: 0.580\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.621\n",
      "Validation Loss: 0.587\n",
      "0.74\n",
      "Fold 7 started at Wed Oct 14 14:32:07 2020\n",
      "Class Weights: [0.88212181 1.15424165]\n",
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 0\n",
      " 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1 1 0\n",
      " 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1\n",
      " 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 0\n",
      " 0 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0\n",
      " 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0\n",
      " 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0\n",
      " 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1\n",
      " 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1\n",
      " 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0\n",
      " 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1\n",
      " 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0 0\n",
      " 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1\n",
      " 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0\n",
      " 0 0 1 1 0 1 1 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.618\n",
      "Validation Loss: 0.611\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.624\n",
      "Validation Loss: 0.611\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.626\n",
      "Validation Loss: 0.614\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.624\n",
      "Validation Loss: 0.609\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.624\n",
      "Validation Loss: 0.607\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.618\n",
      "Validation Loss: 0.608\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.615\n",
      "Validation Loss: 0.607\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.618\n",
      "Validation Loss: 0.607\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.623\n",
      "Validation Loss: 0.610\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.610\n",
      "Validation Loss: 0.611\n",
      "0.67\n",
      "Fold 8 started at Wed Oct 14 14:32:41 2020\n",
      "Class Weights: [0.88310413 1.1525641 ]\n",
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1\n",
      " 0 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1\n",
      " 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0\n",
      " 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 1\n",
      " 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0\n",
      " 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1\n",
      " 1 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1\n",
      " 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1\n",
      " 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0\n",
      " 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0\n",
      " 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 0 1\n",
      " 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0\n",
      " 0 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1\n",
      " 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1\n",
      " 1 0 0 0 1 1 1 1 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.624\n",
      "Validation Loss: 0.580\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.627\n",
      "Validation Loss: 0.574\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.623\n",
      "Validation Loss: 0.570\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.603\n",
      "Validation Loss: 0.570\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.608\n",
      "Validation Loss: 0.569\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.627\n",
      "Validation Loss: 0.570\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.624\n",
      "Validation Loss: 0.567\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.625\n",
      "Validation Loss: 0.568\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.632\n",
      "Validation Loss: 0.565\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.617\n",
      "Validation Loss: 0.570\n",
      "0.7676767676767676\n",
      "Fold 9 started at Wed Oct 14 14:33:16 2020\n",
      "Class Weights: [0.88310413 1.1525641 ]\n",
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0\n",
      " 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
      " 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1\n",
      " 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1\n",
      " 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0\n",
      " 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0\n",
      " 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0\n",
      " 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 0\n",
      " 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0\n",
      " 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 1 0 0\n",
      " 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 1\n",
      " 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0\n",
      " 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 1 1 0 1 1 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.614\n",
      "Validation Loss: 0.628\n",
      "\n",
      " Epoch 2 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.618\n",
      "Validation Loss: 0.640\n",
      "\n",
      " Epoch 3 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.595\n",
      "Validation Loss: 0.625\n",
      "\n",
      " Epoch 4 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.606\n",
      "Validation Loss: 0.634\n",
      "\n",
      " Epoch 5 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.615\n",
      "Validation Loss: 0.647\n",
      "\n",
      " Epoch 6 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.613\n",
      "Validation Loss: 0.627\n",
      "\n",
      " Epoch 7 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.603\n",
      "Validation Loss: 0.634\n",
      "\n",
      " Epoch 8 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.597\n",
      "Validation Loss: 0.627\n",
      "\n",
      " Epoch 9 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.606\n",
      "Validation Loss: 0.633\n",
      "\n",
      " Epoch 10 / 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.609\n",
      "Validation Loss: 0.621\n",
      "0.6868686868686869\n",
      "Bert_davidson | 0.6796  0.6864  0.6850  0.6835 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "f_results = []\n",
    "n_fold = 10\n",
    "counter = 0\n",
    "scores = {}\n",
    "scores.setdefault('fit_time', [])\n",
    "scores.setdefault('score_time', [])\n",
    "scores.setdefault('test_F1', [])\n",
    "scores.setdefault('test_Precision', [])\n",
    "scores.setdefault('test_Recall', [])\n",
    "scores.setdefault('test_Accuracy', [])\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    # set initial loss to infinite\n",
    "    best_valid_loss = float('inf')\n",
    "    \n",
    "\n",
    "    #define a batch size\n",
    "    batch_size = 32\n",
    "    \n",
    "    # tokenize and encode sequences in the training set\n",
    "    tokens_train = tokenizer.batch_encode_plus(\n",
    "        X[train_index].tolist(),\n",
    "        max_length = 100,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # tokenize and encode sequences in the validation set\n",
    "    tokens_val = tokenizer.batch_encode_plus(\n",
    "        X[valid_index].tolist(),\n",
    "        max_length = 100,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # tokenize and encode sequences in the test set\n",
    "    #tokens_test = tokenizer.batch_encode_plus(\n",
    "     #   test_text.tolist(),\n",
    "      #  max_length = 100,\n",
    "       # pad_to_max_length=True,\n",
    "        #truncation=True\n",
    "    #)\n",
    "    \n",
    "    train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "    train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "    train_y = torch.tensor(y[train_index].tolist())\n",
    "\n",
    "    val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "    val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "    val_y = torch.tensor(y[valid_index].tolist())\n",
    "\n",
    "    #test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "    #test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "    #test_y = torch.tensor(test_labels.tolist())\n",
    "\n",
    "    # wrap tensors\n",
    "    train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "    # sampler for sampling the data during training\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "\n",
    "    # dataLoader for train set\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    # wrap tensors\n",
    "    val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "    # sampler for sampling the data during training\n",
    "    val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "    # dataLoader for validation set\n",
    "    val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "    \n",
    "    \n",
    "    #compute the class weights\n",
    "    class_weights = compute_class_weight('balanced', np.unique(y[train_index]), y[train_index])\n",
    "\n",
    "    print(\"Class Weights:\",class_weights)\n",
    "    \n",
    "    # converting list of class weights to a tensor\n",
    "    weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "    # push to GPU\n",
    "    weights = weights.to(device)\n",
    "\n",
    "    # define the loss function\n",
    "    cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "    \n",
    "    \n",
    "\n",
    "    # empty lists to store training and validation loss of each epoch\n",
    "    train_losses=[]\n",
    "    valid_losses=[]\n",
    "\n",
    "    #for each epoch\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "        #train model\n",
    "        train_loss, _ = train(train_dataloader)\n",
    "\n",
    "        #evaluate model\n",
    "        valid_loss, _ = evaluate(val_dataloader)\n",
    "\n",
    "        #save the best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'saved_weights.pt_'+str(fold_n))\n",
    "\n",
    "        # append training and validation loss\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "        print(f'Validation Loss: {valid_loss:.3f}')\n",
    "    \n",
    "    path = 'saved_weights.pt_'+str(fold_n)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      preds = model(val_seq.to(device), val_mask.to(device))\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "    y_valid = y[valid_index]\n",
    "    y_preds = np.argmax(preds, axis = 1)\n",
    "    print(accuracy_score(y_valid, y_preds))\n",
    "    scores['test_F1'].append(f1_score(y_valid, y_preds, average='macro'))\n",
    "    scores['test_Precision'].append(precision_score(y_valid, y_preds, average='macro'))\n",
    "    scores['test_Recall'].append(recall_score(y_valid, y_preds, average='macro'))\n",
    "    scores['test_Accuracy'].append(accuracy_score(y_valid, y_preds))\n",
    "    #scores['test_Specificity'].append(specificity(y_valid, y_preds))\n",
    "    #scores['test_Sensitivity'].append(sensitivity(y_valid, y_preds))\n",
    "\n",
    "print(\"{:<10} | {:<7} {:<7} {:<7} {:<7}\".format(\"Bert_davidson\",\n",
    "                                                           str('%.4f' % (sum(scores['test_F1']) / 10)),\n",
    "                                                           str('%.4f' % (sum(scores['test_Precision']) / 10)),\n",
    "                                                           str('%.4f' % (sum(scores['test_Recall']) / 10)),\n",
    "                                                           str('%.4f' % (sum(scores['test_Accuracy']) / 10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.672\n",
      "Validation Loss: 0.667\n",
      "\n",
      " Epoch 2 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.668\n",
      "Validation Loss: 0.666\n",
      "\n",
      " Epoch 3 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.670\n",
      "Validation Loss: 0.665\n",
      "\n",
      " Epoch 4 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.672\n",
      "Validation Loss: 0.664\n",
      "\n",
      " Epoch 5 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.668\n",
      "Validation Loss: 0.663\n",
      "\n",
      " Epoch 6 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.666\n",
      "Validation Loss: 0.663\n",
      "\n",
      " Epoch 7 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.668\n",
      "Validation Loss: 0.662\n",
      "\n",
      " Epoch 8 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.666\n",
      "Validation Loss: 0.661\n",
      "\n",
      " Epoch 9 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.666\n",
      "Validation Loss: 0.661\n",
      "\n",
      " Epoch 10 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.664\n",
      "Validation Loss: 0.660\n",
      "\n",
      " Epoch 11 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.668\n",
      "Validation Loss: 0.660\n",
      "\n",
      " Epoch 12 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.664\n",
      "Validation Loss: 0.659\n",
      "\n",
      " Epoch 13 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.664\n",
      "Validation Loss: 0.657\n",
      "\n",
      " Epoch 14 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.665\n",
      "Validation Loss: 0.657\n",
      "\n",
      " Epoch 15 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.662\n",
      "Validation Loss: 0.656\n",
      "\n",
      " Epoch 16 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.660\n",
      "Validation Loss: 0.656\n",
      "\n",
      " Epoch 17 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.661\n",
      "Validation Loss: 0.656\n",
      "\n",
      " Epoch 18 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.656\n",
      "Validation Loss: 0.655\n",
      "\n",
      " Epoch 19 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.660\n",
      "Validation Loss: 0.655\n",
      "\n",
      " Epoch 20 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.660\n",
      "Validation Loss: 0.655\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67        85\n",
      "           1       0.57      0.55      0.56        65\n",
      "\n",
      "    accuracy                           0.63       150\n",
      "   macro avg       0.62      0.62      0.62       150\n",
      "weighted avg       0.63      0.63      0.63       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
